{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad2c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-community\n",
    "!pip install langchain-experimental\n",
    "!pip install langchain-huggingface\n",
    "!pip install huggingface_hub\n",
    "!pip install pypdf\n",
    "!pip install neo4j\n",
    "!pip install openai\n",
    "!pip install google-colab\n",
    "!pip install json-repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b231e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import TextLoader #to load Text\n",
    "\n",
    "# from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    " # to create chunks\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from huggingface_hub import HfApi # to get hugging face access\n",
    "import os\n",
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "# from langchain.memory import ChatMessageHistory\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e9d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_key = os.environ.get(\"HF_TOKEN\") #set environment variable named HF_TOKEN with hugging face api key\n",
    "HFapi = HfApi(HF_key)\n",
    "\n",
    "#Embedding model\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=HF_key, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3035d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text generation model or chat model\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    task=\"text-generation\",\n",
    "    temperature = 0.1,\n",
    ")\n",
    "\n",
    "#transforms data into a graph structure\n",
    "llm_transformer = LLMGraphTransformer(llm=llm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55080dc0-1d3e-4120-a7ee-22dc4c00fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loader = TextLoader(\"text.txt\") #for a text file\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"the_shortcut.pdf\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "#create embeddings\n",
    "x = [doc.page_content for doc in documents]\n",
    "document_embeddings = [embeddings.embed_documents(chunk) for chunk in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e2e62-f7fa-45d9-9eab-ecd854bd0b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print document embeddings\n",
    "#document_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a7c7c-a72a-42b1-b608-f03a71f970cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions are used to decode the encoded pdf files. \n",
    "def cidToChar(cidx):\n",
    "    return chr(int(re.findall(r'\\/g(\\d+)',cidx)[0]) + 29)\n",
    "\n",
    "\n",
    "def decode(sentence):\n",
    "  sen = ''\n",
    "  for x in sentence.split('\\n'):\n",
    "    if x != '' and x != '/g3':         # merely to compact the output\n",
    "      abc = re.findall(r'\\/g\\d+',x)\n",
    "      if len(abc) > 0:\n",
    "          for cid in abc: x=x.replace(cid, cidToChar(cid))\n",
    "      sen += repr(x).strip(\"'\")\n",
    "\n",
    "  return re.sub(r'\\s+', ' ', sen)\n",
    "\n",
    "def get_text_from_pdf(file):\n",
    "    loader = PyPDFLoader(file)\n",
    "    pages = loader.load_and_split()\n",
    "    for page in pages[0:30]:\n",
    "        if page.page_content.count('/g') > 3:\n",
    "            page.page_content = decode(page.page_content)\n",
    "            print(page.page_content)\n",
    "    return pages[0:30]\n",
    "\n",
    "texts = get_text_from_pdf(f'the_shortcut.pdf')\n",
    "\n",
    "#texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70007ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check if neo4j database has been connected\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "uri=os.environ.get(\"neo_url\")\n",
    "username=os.environ.get(\"neo_username\")\n",
    "password=os.environ.get(\"neo_pwd\")\n",
    "\n",
    "# Create a driver instance\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "# Function to test the connection\n",
    "def test_connection(driver):\n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            result = session.run(\"RETURN 1\")\n",
    "            for record in result:\n",
    "                print(record)\n",
    "        print(\"Connection to Neo4j established successfully.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error connecting to Neo4j:\", e)\n",
    "\n",
    "test_connection(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d330e257-63c1-437e-ae2a-d56481832f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare the variables to store required info to connect with neo4j db\n",
    "uri=os.environ.get(\"neo_url\")\n",
    "username=os.environ.get(\"neo_username\")\n",
    "password=os.environ.get(\"neo_pwd\")\n",
    "\n",
    "neo4j_vector = Neo4jVector.from_documents(\n",
    "    texts, embedding=embeddings, url=uri, username=username, password=password\n",
    ")\n",
    "\n",
    "\n",
    "#Create and update vector db using embedding_llm\n",
    "#in this case, no relationships are created; only chunks are. To create a relationship, use cypher query. \n",
    "\n",
    "index_name = \"vector\"  # default index name\n",
    "\n",
    "neo4j_vector = Neo4jVector.from_existing_index(\n",
    "    embeddings,\n",
    "    url=uri,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    index_name=index_name,\n",
    ")\n",
    "\n",
    "neo4j_vector.add_documents(texts) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab513f34-7dfd-46c4-a27b-718d3d00fe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute cypher code\n",
    "#display the documents uploaded\n",
    "x = neo4j_vector.query(\"\"\"match (n:Chunk) return distinct n.source as source\"\"\")\n",
    "x = [i['source'] for i in x]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03944241-0226-49a1-8af8-c0f7697c66e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what data the chunks store\n",
    "filtered_source = \"the_shortcut.pdf\" \n",
    "filtered_chunks = neo4j_vector.query(f\"\"\"MATCH (n:Chunk) WHERE n.source = '{filtered_source}' RETURN n\"\"\")\n",
    "print(f\"Chunks: {chunk['n'].keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c96a74-3e7f-44d1-8962-fa3905312ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the 'text' field\n",
    "for chunk in filtered_chunks:\n",
    "    print(f\"Chunk Content: {chunk['n'].get('text')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc42403-2aa7-47a5-957e-4df1f1d95dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what data the chunks store\n",
    "filtered_source = \"the_shortcut.pdf\" \n",
    "filtered_chunks = neo4j_vector.query(f\"\"\"MATCH (n:Chunk) WHERE n.source = '{filtered_source}' RETURN n\"\"\")\n",
    "print(f\"Chunks: {chunk['n'].keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94319502-e0ab-4653-9eb8-4fe402906496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b12eb66-f5d6-43f7-ac3b-c6e3a3da4f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity search over the created vector db\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "greetings = [\"hi\", \"hello\", \"hey\", \"greetings\"]\n",
    "\n",
    "query = \"What is AI?\"\n",
    "\n",
    "if query.strip().lower() in greetings:\n",
    "    print(\"Hi! How can I help you today?\")\n",
    "else:\n",
    "    docs_with_score = neo4j_vector.similarity_search(query)\n",
    "    retriever = neo4j_vector.as_retriever()\n",
    "\n",
    "    #Create the Langchain Chain\n",
    "    chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "        llm, chain_type=\"stuff\", retriever=retriever\n",
    "    )\n",
    "\n",
    "    answer = chain.invoke(\n",
    "        {\"question\": query},\n",
    "        return_only_outputs=True,\n",
    "    )\n",
    "    \n",
    "    print(answer['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35784292-5592-4e21-8bf3-00c2c98bad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_with_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf3695-d137-4903-80ac-2655edaeede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs_with_score[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5a20d0-763d-45d2-b8de-f66d7cff1b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'C:\\\\Users\\\\mm0697\\\\AppData\\\\Local\\\\Temp\\\\tmpw7xisrbe\\\\the_shortcut.pdf'\n",
    "x.split('\\\\')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14943813-d510-44c7-b305-049e659793e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"Who is samiya?\"\n",
    "dws = neo4j_vector.similarity_search(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cd781d-46f1-492c-b80d-9bf083272e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs_with_score[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e53dcdc-3b2e-43d6-8037-dfe98de6a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans2 = chain.invoke(\n",
    "    {\"question\": query2},\n",
    "    return_only_outputs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da874aaf-8ad8-4c60-b142-8fa2f79f5a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans2['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
